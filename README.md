# Diá»…n giáº£i Vision Transformer: Cáº£i thiá»‡n biá»ƒu Ä‘á»“ kÃ­ch hoáº¡t lá»›p á»Ÿ má»—i Head báº±ng Ä‘iá»ƒm tin cáº­y dá»±a vÃ o phÆ°Æ¡ng phÃ¡p biáº¿n Ä‘á»•i hÃ¬nh áº£nh Ä‘áº§u vÃ o

ÄÃ¢y lÃ  pháº§n triá»ƒn khai GitHub cá»§a phÆ°Æ¡ng phÃ¡p ScoreAGC.

## MÃ´ táº£

Vision Transformer (ViT) lÃ  má»™t mÃ´ hÃ¬nh phá»• biáº¿n trong thá»‹ giÃ¡c mÃ¡y tÃ­nh nhá» vÃ o kiáº¿n trÃºc Ä‘áº·c biá»‡t, sá»­ dá»¥ng cÆ¡ cháº¿ tá»± chÃº Ã½ (self-attention) Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng hiá»‡u quáº£ nháº±m Ä‘Æ°a ra dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c. Vá»›i hiá»‡u nÄƒng cao nhÆ° váº­y, viá»‡c hiá»ƒu rÃµ cÃ¡c Ä‘áº·c trÆ°ng mÃ  mÃ´ hÃ¬nh dá»±a vÃ o Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh lÃ  vÃ´ cÃ¹ng quan trá»ng. NghiÃªn cá»©u nÃ y Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p trá»±c quan hÃ³a cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c trÃ­ch xuáº¥t bá»Ÿi ViT báº±ng cÃ¡ch xÃ¡c Ä‘á»‹nh cÃ¡c Báº£n Ä‘á»“ KÃ­ch hoáº¡t theo Lá»›p (CAMs) táº¡i tá»«ng head trong module self-attention. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ quan trá»ng cá»§a tá»«ng CAM vÃ  tá»•ng há»£p chÃºng láº¡i Ä‘á»ƒ táº¡o ra biá»ƒu diá»…n CAM cuá»‘i cÃ¹ng. NgoÃ i ra, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ nhÆ° *Localization metrics* vÃ  *Faithfulness metrics* Ä‘á»ƒ kiá»ƒm tra xem phÆ°Æ¡ng phÃ¡p giáº£i thÃ­ch cá»§a chÃºng tÃ´i cÃ³ thá»±c sá»± cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t Ã½ nghÄ©a vá» quÃ¡ trÃ¬nh ra quyáº¿t Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh hay khÃ´ng.

## Kaggle

Táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn ná»n táº£ng Kaggle.

Äá»ƒ cháº¡y trÃªn Kaggle, báº¡n cáº§n thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:

1. Táº£i vá» hai táº­p tin "ILSVRC2012\_img\_val.tar" vÃ  "ILSVRC2012\_devkit\_t12.tar.gz" tá»« trang [Imagenet](https://www.image-net.org).

2. Táº£i hai táº­p tin nÃ y lÃªn Google Drive cÃ¡ nhÃ¢n cá»§a báº¡n.

3. Báº­t cháº¿ Ä‘á»™ chia sáº» vÃ  sao chÃ©p ID cá»§a hai táº­p tin nÃ y.

4. DÃ¡n ID vÃ o notebook cá»§a chÃºng tÃ´i trÃªn Kaggle lÃ  báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u.

**ÄÃ¡nh giÃ¡ kháº£ nÄƒng Ä‘á»‹nh vá»‹ (Localization)**: [liÃªn káº¿t](https://www.kaggle.com/code/nientrandai/localization-evaluation)

**ÄÃ¡nh giÃ¡ chÃ¨n/xÃ³a (Insertion Deletion)**: [liÃªn káº¿t](https://www.kaggle.com/code/nientrandai/insertion-deletion-evaluation)

**ÄÃ¡nh giÃ¡ Ä‘á»™ tin cáº­y (Faithfulness)**: [liÃªn káº¿t](https://www.kaggle.com/code/nientrandai/faithfulness-evaluation)

**Hiá»ƒn thá»‹ báº£n Ä‘á»“ chÃº Ã½ (Saliency maps)**: [liÃªn káº¿t](https://www.kaggle.com/code/nientrandai/display-saliency-map)

ğŸ“Œ Báº¡n cÃ³ thá»ƒ lÆ°u trá»¯ cÃ¡c báº£n Ä‘á»“ saliency/heatmaps cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p XAI Ä‘á»ƒ sá»­ dá»¥ng sau báº±ng cÃ¡ch lÆ°u chÃºng lÃªn Google Drive vÃ  sá»­ dá»¥ng ID cá»§a chÃºng trong notebook Kaggle cá»§a chÃºng tÃ´i.

## Tham kháº£o GitHub

* Xin gá»­i lá»i cáº£m Æ¡n Ä‘áº·c biá»‡t Ä‘áº¿n cÃ¡c kho GitHub sau Ä‘Ã£ há»— trá»£ cho quÃ¡ trÃ¬nh Ä‘Ã¡nh giÃ¡ vÃ  tham kháº£o cá»§a chÃºng tÃ´i:

[Attention Guided CAM: Giáº£i thÃ­ch trá»±c quan Vision Transformer Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi Self-Attention](https://github.com/LeemSaebom/Attention-Guided-CAM-Visual-Explanations-of-Vision-Transformer-Guided-by-Self-Attention)

[Giáº£i thÃ­ch vÃ  Ä‘Ã¡nh giÃ¡ Vision Transformer: NghiÃªn cá»©u thá»±c nghiá»‡m chuyÃªn sÃ¢u](https://github.com/ValentinCord/TFE_XAI_ViT/tree/main)

[Giáº£i thÃ­ch luá»“ng thÃ´ng tin bÃªn trong Vision Transformer báº±ng cÃ¡ch sá»­ dá»¥ng chuá»—i Markov](https://github.com/XianrenYty/Transition_Attention_Maps)

* Chi tiáº¿t cÃ¡ch sá»­ dá»¥ng:

ChÃºng tÃ´i Ä‘Ã£ clone cÃ¡c kho GitHub nÃ y vÃ  triá»ƒn khai phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh bÃªn trong chÃºng. NgoÃ i ra, chÃºng tÃ´i cÅ©ng sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n mÃ£ cÃ³ sáºµn trong Ä‘Ã³ Ä‘á»ƒ há»— trá»£ Ä‘Ã¡nh giÃ¡ cÃ¡c chá»‰ sá»‘.

* Tham kháº£o cÃ¡c GitHub sau Ä‘á»ƒ xem chi tiáº¿t pháº§n triá»ƒn khai cá»§a ScoreAGC (tham kháº£o pháº§n README Ä‘á»ƒ biáº¿t hÆ°á»›ng dáº«n chi tiáº¿t):

ÄÃ¡nh giÃ¡ Localization: [liÃªn káº¿t](https://github.com/trandainien1/better_agc_ubuntu)

ÄÃ¡nh giÃ¡ Insertion/Deletion: [liÃªn káº¿t](https://github.com/trandainien1/tam)

ÄÃ¡nh giÃ¡ Faithfulness: [liÃªn káº¿t](https://github.com/trandainien1/quantus)
